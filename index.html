<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Magical Hand Particles</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background-color: #050505;
            font-family: 'Courier New', Courier, monospace;
        }
        #canvas-container {
            position: absolute;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            z-index: 1;
        }
        /* Hide the raw video feed, we only want the 3D */
        #input-video {
            position: absolute;
            top: 0;
            left: 0;
            width: 1px;
            height: 1px;
            opacity: 0;
            pointer-events: none;
        }
        #loading {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #00ffcc;
            font-size: 1.2rem;
            text-align: center;
            z-index: 10;
            pointer-events: none;
            transition: opacity 0.5s;
        }
        .instruction {
            font-size: 0.8rem;
            color: #aaa;
            margin-top: 10px;
        }
    </style>
</head>
<body>

    <div id="loading">
        INITIALIZING NEURAL NET...<br>
        <span class="instruction">Allow camera access & raise your hand</span>
    </div>

    <!-- Hidden Video Element for MediaPipe -->
    <video id="input-video" playsinline></video>
    
    <!-- Three.js Container -->
    <div id="canvas-container"></div>

    <!-- 1. Import Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <!-- 2. Import MediaPipe Hands -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>

    <script>
        // --- CONFIGURATION ---
        const PARTICLE_COUNT = 1500; // Lower this if phone is old
        const CAMERA_Z = 50;
        
        // --- GLOBAL VARIABLES ---
        let scene, camera, renderer;
        let particles, positions, colors, sizes, velocities, lifes;
        let geometry;
        let mouse = new THREE.Vector3(0, 0, 0); // Stores mapped hand position
        let lastPos = new THREE.Vector3(0, 0, 0);
        let handDetected = false;
        let hue = 0;

        // --- 1. PROCEDURAL TEXTURE GENERATION ---
        // Creates a soft glow dot without needing external image files
        function createGlowTexture() {
            const canvas = document.createElement('canvas');
            canvas.width = 32;
            canvas.height = 32;
            const context = canvas.getContext('2d');
            const gradient = context.createRadialGradient(16, 16, 0, 16, 16, 16);
            gradient.addColorStop(0, 'rgba(255, 255, 255, 1)');
            gradient.addColorStop(0.2, 'rgba(255, 255, 255, 0.8)');
            gradient.addColorStop(0.5, 'rgba(255, 255, 255, 0.2)');
            gradient.addColorStop(1, 'rgba(0, 0, 0, 0)');
            context.fillStyle = gradient;
            context.fillRect(0, 0, 32, 32);
            const texture = new THREE.Texture(canvas);
            texture.needsUpdate = true;
            return texture;
        }

        // --- 2. THREE.JS SETUP ---
        function initThree() {
            const container = document.getElementById('canvas-container');
            
            scene = new THREE.Scene();
            // Fog to make distant particles fade gracefully
            scene.fog = new THREE.FogExp2(0x050505, 0.002);

            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 1, 1000);
            camera.position.z = CAMERA_Z;

            renderer = new THREE.WebGLRenderer({ antialias: false, alpha: true });
            renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2)); // Optimise for mobile
            renderer.setSize(window.innerWidth, window.innerHeight);
            container.appendChild(renderer.domElement);

            // Create Particle System
            geometry = new THREE.BufferGeometry();
            
            positions = new Float32Array(PARTICLE_COUNT * 3);
            colors = new Float32Array(PARTICLE_COUNT * 3);
            sizes = new Float32Array(PARTICLE_COUNT);
            velocities = []; // Store as array of objects for easier physics logic
            lifes = new Float32Array(PARTICLE_COUNT); // 0 to 1

            const color = new THREE.Color();

            for (let i = 0; i < PARTICLE_COUNT; i++) {
                // Initialize off-screen
                positions[i * 3] = 0;
                positions[i * 3 + 1] = 0;
                positions[i * 3 + 2] = 0;

                color.setHSL(Math.random(), 0.7, 0.5);
                colors[i * 3] = color.r;
                colors[i * 3 + 1] = color.g;
                colors[i * 3 + 2] = color.b;

                sizes[i] = 0;
                lifes[i] = 0; // Dead on start

                velocities.push({
                    x: (Math.random() - 0.5),
                    y: (Math.random() - 0.5),
                    z: (Math.random() - 0.5)
                });
            }

            geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
            geometry.setAttribute('color', new THREE.BufferAttribute(colors, 3));
            geometry.setAttribute('size', new THREE.BufferAttribute(sizes, 1));

            const material = new THREE.PointsMaterial({
                size: 2,
                vertexColors: true,
                map: createGlowTexture(),
                blending: THREE.AdditiveBlending,
                depthWrite: false,
                transparent: true
            });

            particles = new THREE.Points(geometry, material);
            scene.add(particles);

            window.addEventListener('resize', onWindowResize, false);
            animate();
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        // --- 3. ANIMATION LOOP ---
        function animate() {
            requestAnimationFrame(animate);

            // Cycle base hue for rainbow effect
            hue += 0.005; 
            if (hue > 1) hue = 0;

            const positionsArray = geometry.attributes.position.array;
            const colorsArray = geometry.attributes.color.array;
            const sizesArray = geometry.attributes.size.array;

            // Calculate hand speed to affect emission width
            const speed = mouse.distanceTo(lastPos);
            lastPos.copy(mouse);

            // Update every particle
            for (let i = 0; i < PARTICLE_COUNT; i++) {
                // Determine if particle is alive
                if (lifes[i] > 0) {
                    // Update Position based on velocity
                    positionsArray[i * 3] += velocities[i].x;
                    positionsArray[i * 3 + 1] += velocities[i].y;
                    positionsArray[i * 3 + 2] += velocities[i].z;

                    // Drag / Friction
                    velocities[i].x *= 0.96;
                    velocities[i].y *= 0.96;
                    velocities[i].z *= 0.96;

                    // Gravity-ish drift
                    velocities[i].y -= 0.02; 

                    // Age the particle
                    lifes[i] -= 0.015;
                    
                    // Update Size based on life
                    sizesArray[i] = Math.max(0, lifes[i] * 30); // Scale up/down

                } else if (handDetected) {
                    // RESPAWN Logic: Only spawn if dead AND hand is detected
                    // To prevent all particles spawning at once, add a random chance
                    if (Math.random() < 0.1) {
                        lifes[i] = 1.0; // Reset life
                        
                        // Spawn at Hand position
                        positionsArray[i * 3] = mouse.x;
                        positionsArray[i * 3 + 1] = mouse.y;
                        positionsArray[i * 3 + 2] = mouse.z;

                        // Add explosive velocity based on movement
                        const spread = 0.5 + (speed * 2);
                        velocities[i].x = (Math.random() - 0.5) * spread;
                        velocities[i].y = (Math.random() - 0.5) * spread;
                        velocities[i].z = (Math.random() - 0.5) * spread;

                        // Set Color (Cyclical neon)
                        const color = new THREE.Color();
                        // Mix global hue with slight random variation
                        color.setHSL(hue + (Math.random() * 0.1), 1.0, 0.6);
                        colorsArray[i * 3] = color.r;
                        colorsArray[i * 3 + 1] = color.g;
                        colorsArray[i * 3 + 2] = color.b;
                    } else {
                        sizesArray[i] = 0;
                    }
                } else {
                    sizesArray[i] = 0; // Hide if dead and no hand
                }
            }

            // Flag attributes as needing update
            geometry.attributes.position.needsUpdate = true;
            geometry.attributes.color.needsUpdate = true;
            geometry.attributes.size.needsUpdate = true;

            // Rotate scene slightly for depth perception
            if(scene) scene.rotation.y = Math.sin(Date.now() * 0.0005) * 0.1;

            renderer.render(scene, camera);
        }

        // --- 4. MEDIAPIPE HAND TRACKING ---
        function onResults(results) {
            const loading = document.getElementById('loading');
            
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                loading.style.opacity = 0;
                handDetected = true;
                
                // Get the first hand detected
                const landmarks = results.multiHandLandmarks[0];
                
                // Track Index Finger Tip (Landmark 8)
                const indexTip = landmarks[8];

                // Convert Video Coordinates (0-1) to Three.js World Coordinates
                // We use vector unproject logic logic roughly mapped to our camera Z
                
                // 1. Map 0..1 to -1..1 (NDC)
                // Note: We invert X because the webcam is mirrored usually
                const ndcX = (1 - indexTip.x) * 2 - 1; 
                const ndcY = -(indexTip.y * 2 - 1); // Flip Y

                // 2. Project into 3D space
                const vector = new THREE.Vector3(ndcX, ndcY, 0.5);
                vector.unproject(camera);
                
                const dir = vector.sub(camera.position).normalize();
                const distance = -camera.position.z / dir.z;
                
                // This gives us the position at Z=0 plane
                const pos = camera.position.clone().add(dir.multiplyScalar(distance));
                
                // Smoothing (Linear Interpolation) for less jitter
                mouse.lerp(pos, 0.2);
                // Fake depth based on hand size (optional, purely visual)
                mouse.z = (indexTip.z * -10); 
                
            } else {
                handDetected = false;
            }
        }

        // --- INIT SEQUENCE ---
        initThree();

        const videoElement = document.getElementById('input-video');
        const hands = new Hands({locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
        }});

        hands.setOptions({
            maxNumHands: 1, // Optimize for phone: 1 hand only
            modelComplexity: 1, // 0 is fastest, 1 is balanced
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        hands.onResults(onResults);

        const cameraUtils = new Camera(videoElement, {
            onFrame: async () => {
                await hands.send({image: videoElement});
            },
            width: 640, // Lower res for better performance on phone
            height: 480
        });

        cameraUtils.start().catch(err => {
            console.error("Camera error:", err);
            document.getElementById('loading').innerText = "CAMERA PERMISSION DENIED";
        });

    </script>
</body>
</html>
